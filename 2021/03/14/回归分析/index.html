<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>回归分析 | Night Stalker</title><meta name="description" content="回归分析回归分析的任务就是通过研究自变量X和因变量Y的相关关系，尝试解释Y的形成机制，进而达到通过X去预测Y的目的； 细分可以分为如下任务：  哪些X与Y真的相关； 有用的X变量与Y的相关关系是正还是负； 赋予不同X权重，表征不同变量之间的相对重要性。  分类   类型 模型 Y的特点 例子    线性回归 OLS,GLS(最小二乘) 连续数值型变量 GDP,产量   0-1回归 logistic"><meta name="keywords" content="数学建模"><meta name="author" content="NS"><meta name="copyright" content="NS"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://yoursite.com/2021/03/14/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="回归分析"><meta property="og:url" content="http://yoursite.com/2021/03/14/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/"><meta property="og:site_name" content="Night Stalker"><meta property="og:description" content="回归分析回归分析的任务就是通过研究自变量X和因变量Y的相关关系，尝试解释Y的形成机制，进而达到通过X去预测Y的目的； 细分可以分为如下任务：  哪些X与Y真的相关； 有用的X变量与Y的相关关系是正还是负； 赋予不同X权重，表征不同变量之间的相对重要性。  分类   类型 模型 Y的特点 例子    线性回归 OLS,GLS(最小二乘) 连续数值型变量 GDP,产量   0-1回归 logistic"><meta property="og:image" content="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><meta property="article:published_time" content="2021-03-13T16:00:00.000Z"><meta property="article:modified_time" content="2021-03-24T12:09:04.041Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="prev" title="时间序列分析" href="http://yoursite.com/2021/03/20/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/"><link rel="next" title="相关系数和假设检验" href="http://yoursite.com/2021/03/13/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E5%92%8C%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=2700190935,3142448700&amp;fm=26&amp;gp=0.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">27</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">7</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">4</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#回归分析"><span class="toc-number">1.</span> <span class="toc-text">回归分析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#分类"><span class="toc-number">1.1.</span> <span class="toc-text">分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#一元线性回归"><span class="toc-number">1.2.</span> <span class="toc-text">一元线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模型"><span class="toc-number">1.2.1.</span> <span class="toc-text">模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#内生性"><span class="toc-number">1.2.2.</span> <span class="toc-text">内生性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#含有交互项的自变量"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">含有交互项的自变量</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用Stata进行实例操作"><span class="toc-number">1.3.</span> <span class="toc-text">使用Stata进行实例操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#将所有量都加入回归分析"><span class="toc-number">1.3.0.1.</span> <span class="toc-text">将所有量都加入回归分析</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#标准化回归系数"><span class="toc-number">1.3.1.</span> <span class="toc-text">标准化回归系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#异方差"><span class="toc-number">1.3.2.</span> <span class="toc-text">异方差</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#异方差的假设检验"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">异方差的假设检验</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#使用OLS-稳健的标准误"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">使用OLS+稳健的标准误</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#多重共线性"><span class="toc-number">1.4.</span> <span class="toc-text">多重共线性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#检验多重共线性"><span class="toc-number">1.4.1.</span> <span class="toc-text">检验多重共线性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#解决办法"><span class="toc-number">1.4.2.</span> <span class="toc-text">解决办法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#向前逐步回归"><span class="toc-number">1.4.2.1.</span> <span class="toc-text">向前逐步回归</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#向后逐步回归"><span class="toc-number">1.4.3.</span> <span class="toc-text">向后逐步回归</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#岭回归和lasso回归"><span class="toc-number">1.5.</span> <span class="toc-text">岭回归和lasso回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#stata进行lasso回归"><span class="toc-number">1.5.1.</span> <span class="toc-text">stata进行lasso回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lasso回归使用场景"><span class="toc-number">1.5.2.</span> <span class="toc-text">lasso回归使用场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#岭回归的python实现"><span class="toc-number">1.5.3.</span> <span class="toc-text">岭回归的python实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lasso回归的python实现"><span class="toc-number">1.5.4.</span> <span class="toc-text">lasso回归的python实现</span></a></li></ol></li></ol></li></ol></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Night Stalker</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">回归分析</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2021-03-14 00:00:00"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2021-03-14</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2021-03-24 20:09:04"><i class="fas fa-history fa-fw"></i> 更新于 2021-03-24</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/">数学建模</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="回归分析"><a href="#回归分析" class="headerlink" title="回归分析"></a>回归分析</h1><p>回归分析的任务就是通过研究自变量X和因变量Y的相关关系，尝试解释Y的形成机制，进而达到通过X去预测Y的目的；</p>
<p>细分可以分为如下任务：</p>
<ul>
<li>哪些X与Y真的相关；</li>
<li>有用的X变量与Y的相关关系是正还是负；</li>
<li>赋予不同X权重，表征不同变量之间的相对重要性。</li>
</ul>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><table>
<thead>
<tr>
<th>类型</th>
<th>模型</th>
<th>Y的特点</th>
<th>例子</th>
</tr>
</thead>
<tbody><tr>
<td>线性回归</td>
<td>OLS,GLS(最小二乘)</td>
<td>连续数值型变量</td>
<td>GDP,产量</td>
</tr>
<tr>
<td>0-1回归</td>
<td>logistic回归</td>
<td>二值变量</td>
<td>是否违约</td>
</tr>
<tr>
<td>定序回归</td>
<td>probit定序回归</td>
<td>定序变量</td>
<td>等级评定</td>
</tr>
<tr>
<td>计数回归</td>
<td>泊松回归</td>
<td>计数变量</td>
<td>每分钟车流量</td>
</tr>
<tr>
<td>生存回归</td>
<td>Cox等比例风险回归</td>
<td>生存变量（截断数据）</td>
<td>企业，产品寿命</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>数据种类</th>
<th>定义</th>
<th>建模方法</th>
</tr>
</thead>
<tbody><tr>
<td>横截面数据</td>
<td>在某一时间点收集的不同对象的数据</td>
<td>多元线性回归</td>
</tr>
<tr>
<td>时间序列数据</td>
<td>同一对象在不同时间连续观察所得到的数据</td>
<td>AR,MA,ARMA,ARIMA,GARCH,VAR</td>
</tr>
<tr>
<td>面板数据</td>
<td>横截面数据和时间序列数据的总和</td>
<td>固定效应和随机效应，静态面板和动态面板</td>
</tr>
</tbody></table>
<p>​    </p>
<h2 id="一元线性回归"><a href="#一元线性回归" class="headerlink" title="一元线性回归"></a>一元线性回归</h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>假设x为自变量，y为因变量，且满足如下线性关系：<br>$$<br>y_i = \beta_0+\beta_1x_i +\mu_i<br>$$<br>$\beta_0,\beta_1$为回归系数，$\mu_i$为无法直接观测的满足一定条件的扰动项；</p>
<p>预测值$\hat{y_i} = \hat{\beta_0} + \hat{\beta_1} x_i$，参数求法依然是使得代价函数（残差平方和）最小；</p>
<p>残差$\hat{\mu_i}=y_i-\hat{\beta_0}-\hat{\beta_1 }x_i$</p>
<blockquote>
<p>自变量和因变量因为变换而转化为线性模型也可以称为线性，如$lny_i = \beta_0+\beta_1x_i +\mu_i$</p>
</blockquote>
<h3 id="内生性"><a href="#内生性" class="headerlink" title="内生性"></a>内生性</h3><p>线性回归模型中的误差项$\mu$与所有的自变量$x$都不相关，则该回归模型具有外生性；否则称之为内生性，若有内生性，则会导致回归系数估计的不准确，不满足无偏性和一致性。</p>
<p>误差项包含所有与y相关但是未添加到回归模型中的变量，若这些变量与已添加的自变量相关，则存在内生性；</p>
<p>内生性检验：</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">times = <span class="number">300</span>;</span><br><span class="line">R = <span class="built_in">zeros</span>(times, <span class="number">1</span>);</span><br><span class="line">K = <span class="built_in">zeros</span>(times, <span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:times</span><br><span class="line">    n = <span class="number">30</span>;<span class="comment">% 样本数据量</span></span><br><span class="line">    x1 = <span class="number">-10</span>+<span class="built_in">rand</span>(n,<span class="number">1</span>)*<span class="number">20</span>;<span class="comment">% x1在-10~10上均匀分布</span></span><br><span class="line">    u1 = normrnd(<span class="number">0</span>,<span class="number">5</span>,n,<span class="number">1</span>)-<span class="built_in">rand</span>(n,<span class="number">1</span>);<span class="comment">%随机生成一组随机数</span></span><br><span class="line">    x2 = <span class="number">0.3</span>*x1+u1;<span class="comment">%x2和x1具有相关性加上随机数导致不确定</span></span><br><span class="line">    u = normrnd(<span class="number">0</span>,<span class="number">1</span>,n,<span class="number">1</span>);<span class="comment">%扰动项服从标准正态分布</span></span><br><span class="line">    y = <span class="number">0.5</span>+<span class="number">2</span>*x1+<span class="number">5</span>*x2+u;</span><br><span class="line">    k = (n*sum(x1.*y)-sum(x1)*sum(y))/(n*sum(x1.*x1)-sum(x1)*sum(x1));<span class="comment">%斜率k</span></span><br><span class="line">    K(<span class="built_in">i</span>) = k;</span><br><span class="line">    u = x2+u;<span class="comment">%忽略x2所以扰动项加上</span></span><br><span class="line">    r = corrcoef(x1,u);<span class="comment">%2*2的相关矩阵</span></span><br><span class="line">    R(<span class="built_in">i</span>) = r(<span class="number">2</span>,<span class="number">1</span>);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="built_in">plot</span>(R,K,<span class="string">'*'</span>)</span><br><span class="line">xlabel(<span class="string">"相关系数"</span>)</span><br><span class="line">ylabel(<span class="string">"k的估计值"</span>)</span><br></pre></td></tr></table></figure>

<p>我们通过蒙特卡罗模拟发现内生性越强（u和x1的相关系数越大），k的偏差越大；</p>
<p>但事实上要做到无内生性实在太难，因为自变量一般都比较多，于是我们将解释变量（就是因变量）分为核心解释变量与控制变量两类；</p>
<p><strong>核心解释变量</strong>：最感兴趣的变量；</p>
<p><strong>控制变量</strong>：并无太大兴趣，但放入回归方程用于控制对被解释变量有影响的遗漏因素；</p>
<p>实际应用中，我们只要保证$\mu$与核心解释变量不相关即可；</p>
<h4 id="含有交互项的自变量"><a href="#含有交互项的自变量" class="headerlink" title="含有交互项的自变量"></a>含有交互项的自变量</h4><p>因变量对一个解释变量的偏效应，弹性或半弹性，有时很自然地取决于另个一个解释变量的大小，比如，下式中：<br>$$<br>price = \beta_0+\beta_1 sqrft +\beta_2 bdrms+\beta_3 sqrft*bdrms+ \beta_4 bthrms+\mu<br>$$<br>$bdrms$对$price$的偏效应：<br>$$<br>\frac{\Delta price}{\Delta bdrms}=\beta_2+\beta_3 sqrft<br>$$<br>若$\beta_3&gt;0$则说明$sqrft$与$bdrms$间存在着正交互效应。</p>
<h2 id="使用Stata进行实例操作"><a href="#使用Stata进行实例操作" class="headerlink" title="使用Stata进行实例操作"></a>使用Stata进行实例操作</h2><p>使用Stata进行回归拟合，</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">regress</span> y x1 x2 ... xk</span><br></pre></td></tr></table></figure>

<p>默认使用最小二乘法求；</p>
<ul>
<li><p>得到的结果中，SS栏Model是SSR，Residual是SSE，Total是SST；df是自由度；</p>
</li>
<li><p>R-squared和Adj R-squared是$R^2$和调整后的$R^2$；我们更倾向于使用后者，原因如下：</p>
</li>
<li><p>F（n,m)和prob &gt; F 是联合显著性检验，用于判断是否有$\beta_0=\beta_1=\dots=\beta_k = 0$；而我们的回归是有效的当概率$&lt;0.05$，此时拒绝原假设($H_0：$回归系数为0)；</p>
</li>
</ul>
<p>我们引入的自变量越多，拟合优度会越大，但我们倾向于使用调整之后的拟合优度，如果新引入的变量对SSE的减少程度特别少，那么调整之后的拟合优度反而会减少；</p>
<p>下面一张表中</p>
<ul>
<li><p>coef就是估计出来的各项$\beta$，其中_cons是常数，也就是$\beta_0$;</p>
</li>
<li><p>Std.Err是标准误差</p>
</li>
<li><p>t = coef / Std.Err</p>
</li>
<li><p>P&gt;|t|,就是相关系数检验时所要求的p值，p值小于0.05表示在95%置信区间下，该回归系数显著的异于0</p>
</li>
<li><p>95% Conf. Interval 就是$\beta$值应该落在的区间，称为置信区间</p>
</li>
</ul>
<h4 id="将所有量都加入回归分析"><a href="#将所有量都加入回归分析" class="headerlink" title="将所有量都加入回归分析"></a>将所有量都加入回归分析</h4><ul>
<li>看Prob&gt;F的值是否在0.05之内</li>
<li>找p值在0.05以下的因素（置信水平为95%时，若选取90%则0.1以下即可），作为显著变量；</li>
<li>coef即为对应变量前的$\beta$</li>
</ul>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 清除所有变量</span></span><br><span class="line"><span class="keyword">clear</span></span><br><span class="line"><span class="comment">// 清屏 和 matlab的clc类似</span></span><br><span class="line">cls </span><br><span class="line"><span class="comment">// 导入数据（其实是我们直接在界面上粘贴过来的，我们用鼠标点界面导入更方便 本条请删除后再复制到论文中，如果评委老师看到了就知道这不是你写的了）</span></span><br><span class="line"><span class="comment">// import excel "D:\BaiduNetdiskDownload\正课视频的课件和代码\第7讲.多元回归分析\代码和例题数据\课堂中讲解的奶粉数据.xlsx", sheet("Sheet1") firstrow</span></span><br><span class="line">import excel <span class="string">"D:\BaiduNetdiskDownload\正课视频的课件和代码\第7讲.多元回归分析\代码和例题数据\课堂中讲解的奶粉数据.xlsx"</span>, sheet(<span class="string">"Sheet1"</span>) firstrow</span><br><span class="line"><span class="comment">// 定量变量的描述性统计</span></span><br><span class="line"><span class="keyword">summarize</span> 团购价元 评价量 商品毛重kg</span><br><span class="line"><span class="comment">// 定性变量的频数分布，并得到相应字母开头的虚拟变量</span></span><br><span class="line"><span class="keyword">tabulate</span> 配方,<span class="keyword">gen</span>(A)</span><br><span class="line"><span class="keyword">tabulate</span> 奶源产地 ,<span class="keyword">gen</span>(B)</span><br><span class="line"><span class="keyword">tabulate</span> 国产或进口 ,<span class="keyword">gen</span>(C)</span><br><span class="line"><span class="keyword">tabulate</span> 适用年龄岁 ,<span class="keyword">gen</span>(<span class="keyword">D</span>)</span><br><span class="line"><span class="keyword">tabulate</span> 包装单位 ,<span class="keyword">gen</span>(<span class="keyword">E</span>)</span><br><span class="line"><span class="keyword">tabulate</span> 分类 ,<span class="keyword">gen</span>(F)</span><br><span class="line"><span class="keyword">tabulate</span> 段位 ,<span class="keyword">gen</span>(<span class="keyword">G</span>)</span><br><span class="line"><span class="comment">// 下面进行回归</span></span><br><span class="line"><span class="keyword">regress</span> 评价量 团购价元 商品毛重kg</span><br><span class="line"><span class="comment">// 下面的语句可帮助我们把回归结果保存在Word文档中</span></span><br><span class="line"><span class="comment">// 在使用之前需要运行下面这个代码来安装下这个功能包（运行一次之后就可以注释掉了）</span></span><br><span class="line"><span class="comment">// ssc install reg2docx, all replace</span></span><br><span class="line"><span class="comment">// 如果安装出现connection timed out的错误，可以尝试换成手机热点联网，如果手机热点也不能下载，就不用这个命令吧，可以自己做一个回归结果表，如果觉得麻烦就直接把回归结果截图。</span></span><br><span class="line"><span class="keyword">est</span> store m1</span><br><span class="line">reg2docx m1 using m1.docx, <span class="keyword">replace</span></span><br><span class="line"><span class="comment">// *** p&lt;0.01  ** p&lt;0.05 * p&lt;0.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Stata会自动剔除多重共线性的变量</span></span><br><span class="line"><span class="keyword">regress</span> 评价量 团购价元 商品毛重kg A1 A2 A3 B1 B2 B3 B4 B5 B6 B7 B8 B9 C1 C2 D1 D2 D3 D4 D5 E1 E2 E3 E4 F1 F2 G1 G2 G3 G4</span><br><span class="line"><span class="keyword">est</span> store m2</span><br><span class="line">reg2docx m2 using m2.docx, <span class="keyword">replace</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 得到标准化回归系数</span></span><br><span class="line"><span class="keyword">regress</span> 评价量 团购价元 商品毛重kg, b </span><br><span class="line"></span><br><span class="line"><span class="comment">// 画出残差图</span></span><br><span class="line"><span class="keyword">regress</span> 评价量 团购价元 商品毛重kg A1 A2 A3 B1 B2 B3 B4 B5 B6 B7 B8 B9 C1 C2 D1 D2 D3 D4 D5 E1 E2 E3 E4 F1 F2 G1 G2 G3 G4</span><br><span class="line"><span class="keyword">rvfplot</span> </span><br><span class="line"><span class="comment">// 残差与拟合值的散点图</span></span><br><span class="line"><span class="keyword">graph</span> export a1.png ,<span class="keyword">replace</span></span><br><span class="line"><span class="comment">// 残差与自变量团购价的散点图</span></span><br><span class="line"><span class="keyword">rvpplot</span>  团购价元</span><br><span class="line"><span class="keyword">graph</span> export a2.png ,<span class="keyword">replace</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 为什么评价量的拟合值会出现负数？</span></span><br><span class="line"><span class="comment">// 描述性统计并给出分位数对应的数值</span></span><br><span class="line"><span class="keyword">summarize</span> 评价量,<span class="keyword">d</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 作评价量的概率密度估计图</span></span><br><span class="line"><span class="keyword">kdensity</span> 评价量 </span><br><span class="line"><span class="keyword">graph</span> export a3.png ,<span class="keyword">replace</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 异方差BP检验</span></span><br><span class="line"><span class="keyword">estat</span> <span class="keyword">hettest</span> ,rhs iid</span><br><span class="line"></span><br><span class="line"><span class="comment">// 异方差怀特检验</span></span><br><span class="line"><span class="keyword">estat</span> <span class="keyword">imtest</span>,white</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用OLS + 稳健的标准误</span></span><br><span class="line"><span class="keyword">regress</span> 评价量 团购价元 商品毛重kg A1 A2 A3 B1 B2 B3 B4 B5 B6 B7 B8 B9 C1 C2 D1 D2 D3 D4 D5 E1 E2 E3 E4 F1 F2 G1 G2 G3 G4, r</span><br><span class="line"><span class="keyword">est</span> store m3</span><br><span class="line">reg2docx m3 using m3.docx, <span class="keyword">replace</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 计算VIF</span></span><br><span class="line"><span class="keyword">estat</span>  <span class="keyword">vif</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 逐步回归（一定要注意完全多重共线性的影响）</span></span><br><span class="line"><span class="comment">// 向前逐步回归（后面的r表示稳健的标准误）</span></span><br><span class="line"><span class="keyword">stepwise</span> <span class="keyword">reg</span> 评价量 团购价元 商品毛重kg A1 A3 B1 B2 B3 B4 B5 B6 B7 B9 C1 D1 D2 D3 D4 E1 E2 E3 F1 G1 G2 G3,  r pe(0.05)</span><br><span class="line"><span class="comment">// 向后逐步回归（后面的r表示稳健的标准误）</span></span><br><span class="line"><span class="keyword">stepwise</span> <span class="keyword">reg</span> 评价量 团购价元 商品毛重kg A1 A3 B1 B2 B3 B4 B5 B6 B7 B9 C1 D1 D2 D3 D4 E1 E2 E3 F1 G1 G2 G3,  r <span class="keyword">pr</span>(0.05)</span><br><span class="line"><span class="comment">// 向后逐步回归的同时使用标准化回归系数（在r后面跟上一个b即可）</span></span><br><span class="line"><span class="keyword">stepwise</span> <span class="keyword">reg</span> 评价量 团购价元 商品毛重kg A1 A3 B1 B2 B3 B4 B5 B6 B7 B9 C1 D1 D2 D3 D4 E1 E2 E3 F1 G1 G2 G3,  r b <span class="keyword">pr</span>(0.05)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// (1) 用已知变量生成新的变量 </span></span><br><span class="line"><span class="keyword">generate</span> lny = <span class="built_in">log</span>(评价量)  </span><br><span class="line"><span class="keyword">generate</span> price_square = 团购价元 ^2</span><br><span class="line"><span class="keyword">generate</span> interaction_term = 团购价元*商品毛重kg</span><br><span class="line"></span><br><span class="line"><span class="comment">// (2) 修改变量名称，因为用中文命名变量名称有时候可能容易出现未知Bug</span></span><br><span class="line"><span class="keyword">rename</span> 团购价元 price</span><br></pre></td></tr></table></figure>

<p>如果出现$R^2$过低，不用担心，预测性回归更看重$R^2$与1的贴近程度，解释性回归更多地关注模型整体显著性以及自变量的统计显著性和经济意义显著性。</p>
<p>或者对模型进行调整，对数据取对数或是平方。也可能是数据中存在异常值或数据分布不均匀。</p>
<h3 id="标准化回归系数"><a href="#标准化回归系数" class="headerlink" title="标准化回归系数"></a>标准化回归系数</h3><p>为了更精准地研究影响评价量的重要因素，可以考虑使用标准化回归系数；</p>
<p>对数据进行标准化得到新的变量值，新变量构成的回归方程称为标准化回归方程，回归后相应可得到标准化回归系数；</p>
<p><strong>标准化回归系数越大，说明对因变量的影响越大</strong>，但只关注显著变量的回归系数。</p>
<blockquote>
<p>stata进行标准化回归</p>
</blockquote>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">regress</span> y x1 x2 ... , b</span><br></pre></td></tr></table></figure>



<h3 id="异方差"><a href="#异方差" class="headerlink" title="异方差"></a>异方差</h3><p><a href="https://baike.baidu.com/item/%E5%BC%82%E6%96%B9%E5%B7%AE%E6%80%A7" target="_blank" rel="noopener">异方差</a>的存在会有如下特征：</p>
<ul>
<li>OLS估计出来的回归系数是无偏的，一致的；</li>
<li>假设检验无法使用</li>
<li>OLS估计量不再是最优线性无偏估计量</li>
</ul>
<p>解决方法：</p>
<ul>
<li>使用OLS和稳健的标准误</li>
<li>广义最小二乘法GLS,原理：方差较小的数据含有的信息更多，给予更大的权重</li>
</ul>
<p>Stock and Waston推荐在大多数情况下使用第一种方法；</p>
<p>通过残差图检验异方差；</p>
<p>使用stata命令</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">rvfplot</span> (画残差与拟合值的散点图)</span><br><span class="line"><span class="keyword">rvpplot</span> x (画残差与自变量的散点图)</span><br></pre></td></tr></table></figure>

<h4 id="异方差的假设检验"><a href="#异方差的假设检验" class="headerlink" title="异方差的假设检验"></a>异方差的假设检验</h4><p>主要包括BP检验和怀特检验，后者还包括平方项和交叉项，因此BP检验可以看做是怀特检验的特例；</p>
<p>Stata命令（在回归后使用）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">estat hettest ,rhs iid</span><br></pre></td></tr></table></figure>

<p>在BP检验中，我们的原假设是不存在异方差，倘若执行上述代码得到结果后发现求得的p值（软件的显示为Prob &gt; chi2）小于0.05，则说明在95%的置信水平下我们可以拒绝原假设，即我们认为扰动项存在异方差；</p>
<h4 id="使用OLS-稳健的标准误"><a href="#使用OLS-稳健的标准误" class="headerlink" title="使用OLS+稳健的标准误"></a>使用OLS+稳健的标准误</h4><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">regress</span> y x1 x2 ... xk, robust</span><br></pre></td></tr></table></figure>



<h2 id="多重共线性"><a href="#多重共线性" class="headerlink" title="多重共线性"></a>多重共线性</h2><p>若数据矩阵不满列秩，即某一解释变量可以由其他解释变量线性表出，则说明存在<strong>严格多重共线性</strong>，它会使得回归系数的估计变得不准确；</p>
<h3 id="检验多重共线性"><a href="#检验多重共线性" class="headerlink" title="检验多重共线性"></a>检验多重共线性</h3><p>方差膨胀因子$VIF$;假设现在有$k$个自变量，那么第$m$个自变量的$VIF_m=\frac{1}{1-R_{1\sim k/m}^2}$</p>
<p>而$R_{1\sim k/m}^2$是将第$m$个变量作为因变量，对剩下的$k-1$个自变量回归得到的拟合优度；$VIF_m$越大说明第$m$个变量与其他变量的相关性越大；</p>
<p>按一般规则，有整个数据表的$VIF$为$max{VIF_1,VIF_2,\dots,VIF_k}$,一般当$VIF$大于10时说明多重共线性较为严重了；</p>
<h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><h4 id="向前逐步回归"><a href="#向前逐步回归" class="headerlink" title="向前逐步回归"></a>向前逐步回归</h4><p>将自变量逐个引入模型，每引入一个都进行检验，显著时才加入回归模型；</p>
<p>Defect:随着变量的加入，原来显著的变量可能变得不显著了，但并没有将其从回归方程中剔除；</p>
<h3 id="向后逐步回归"><a href="#向后逐步回归" class="headerlink" title="向后逐步回归"></a>向后逐步回归</h3><p>先将所有变量放入模型，然后尝试将自变量剔除，看整个模型解释因变量的差异是否有显著变化，之后将最没有解释力的自变量剔除；</p>
<p>逐步回归的结果有可能不同，不要轻易使用逐步回归，因为剔除自变量后很可能产生新的问题；更加完善的求法是每种情况都尝试一遍（全局筛选），最终一共有$2^k - 1$种可能，但问题是变量太多的话计算量会非常大；</p>
<h2 id="岭回归和lasso回归"><a href="#岭回归和lasso回归" class="headerlink" title="岭回归和lasso回归"></a>岭回归和lasso回归</h2><p>岭回归和lasso回归在OLS回归模型上添加了不同的惩罚项，该惩罚项由回归系数的函数构成，；一方面，加入的惩罚项能够识别出模型中不重要的变量，另一方面加入的惩罚项能够让模型变得可以估计；</p>
<p>岭回归的原理可以参见<a href="https://nightstalker007.github.io/2021/02/13/logistic%E5%9B%9E%E5%BD%92/" target="_blank" rel="noopener">logistic回归</a>,岭回归和lasso在<a href="https://zhuanlan.zhihu.com/p/30535220" target="_blank" rel="noopener">机器学习算法实践-岭回归和LASSO</a>中均有介绍；两种回归的主要区别就在于惩罚项的不同,lasso使用绝对值的一阶函数，而岭回归使用平方和形式的二阶函数；lasso回归更为<strong>常用</strong>，它的优点是可以将不重要的变量的回归系数压缩至0，当岭回归的变量回归系数一般不会为0，但它的缺点是只能使用近似估计算法来求解。</p>
<h3 id="stata进行lasso回归"><a href="#stata进行lasso回归" class="headerlink" title="stata进行lasso回归"></a>stata进行lasso回归</h3><p>若数据量纲不同，要先使用egen 名称 = std（变量）命令来对变量进行标准化；</p>
<p>采用K折交叉验证来选择最佳调整参数，过程：将样本分为K等分，每次取一个样本不用（1,2，…，n）用其他K-1个样本作为训练集估计模型，再以此预测第一个样本，并计算均方预测误差（MSPE），将所有子样本的MSPE加总得到整个样本的MSPE，再调整参数使得这个总值最小，得到最佳的预测能力。</p>
<p>使用命令：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cvlasso 变量1 变量2 ... ，lopt seed(500)</span><br></pre></td></tr></table></figure>

<p>500为设置的随机数种子，算法默认选择K=10；</p>
<p>运行结果中会根据MSPE的大小来选择$\lambda$,然后根据选择的$\lambda$进行变量系数的计算；第一列Lasso下即为lasso回归计算的变量系数，而第二列Post-est OLS是仅根据Lasso进行变量筛选，然后再用OLS回归计算变量系数。</p>
<h3 id="lasso回归使用场景"><a href="#lasso回归使用场景" class="headerlink" title="lasso回归使用场景"></a>lasso回归使用场景</h3><ul>
<li>首先使用OLS进行回归，然后计算方差膨胀因子VIF,若其大于10则说明存在多重共线性的问题，此时需要对变量进行筛选；</li>
<li>lasso回归进行变量筛选（可以作为逐步回归法筛选自变量的替代）</li>
<li>使用lasso变量筛选后的变量视为自变量，进行回归，并分析回归结果。</li>
</ul>
<h3 id="岭回归的python实现"><a href="#岭回归的python实现" class="headerlink" title="岭回归的python实现"></a>岭回归的python实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">()</span>:</span></span><br><span class="line">    ex = load_workbook(<span class="string">'D:\BaiduNetdiskDownload\更新视频的课件和代码\更新4 岭回归和lasso回归\数据和拓展资料\棉花产量论文作业的数据.xlsx'</span>)</span><br><span class="line">    s = ex.active</span><br><span class="line">    x = np.zeros(shape=(<span class="number">18</span>,<span class="number">5</span>))</span><br><span class="line">    y = np.ones(<span class="number">18</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>,<span class="number">20</span>):</span><br><span class="line">        y[i<span class="number">-2</span>] = s.cell(i,<span class="number">2</span>).value</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">3</span>,<span class="number">8</span>):</span><br><span class="line">            x[i<span class="number">-2</span>][j<span class="number">-3</span>] = s.cell(i,j).value</span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">22</span>)</span><br><span class="line">    <span class="comment"># 先绘制不同alpha条件下的岭迹图</span></span><br><span class="line">    alphas = np.logspace(<span class="number">-3</span>,<span class="number">10</span>,<span class="number">200</span>)</span><br><span class="line">    coefs = []</span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> alphas:</span><br><span class="line">        model = Ridge(alpha=a, fit_intercept=<span class="literal">False</span>)</span><br><span class="line">        model.fit(x_train, y_train)</span><br><span class="line">        coefs.append(model.coef_)</span><br><span class="line">    <span class="comment"># 绘图展示结果</span></span><br><span class="line">    ax = plt.gca()</span><br><span class="line">    ax.plot(alphas, coefs)</span><br><span class="line">    ax.set_xscale(<span class="string">'log'</span>)</span><br><span class="line">    ax.set_xlim(ax.get_xlim()[::<span class="number">-1</span>])  <span class="comment"># 将横坐标逆转</span></span><br><span class="line">    plt.xlabel(<span class="string">'alpha'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'omega'</span>)</span><br><span class="line">    plt.title(<span class="string">'Ridge trace figure'</span>)</span><br><span class="line">    <span class="comment"># plt.axis('tight')  # 'tight'设置刻度线足以显示所有数据</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 选取到最优的alpha</span></span><br><span class="line">    model = RidgeCV(alphas=alphas,fit_intercept=<span class="literal">False</span>)</span><br><span class="line">    model.fit(x_train, y_train)</span><br><span class="line">    print(model.alpha_)</span><br><span class="line">    y_predict = model.predict(x_test)</span><br><span class="line">    print(<span class="string">'预测数据:'</span>,y_predict)</span><br><span class="line">    print(<span class="string">'实际数据:'</span>,y_test)</span><br><span class="line">    print(<span class="string">'R^2 为：'</span>,r2_score(y_test, y_predict))</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>

<h3 id="lasso回归的python实现"><a href="#lasso回归的python实现" class="headerlink" title="lasso回归的python实现"></a>lasso回归的python实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">()</span>:</span></span><br><span class="line">    ex = load_workbook(<span class="string">'D:\BaiduNetdiskDownload\更新视频的课件和代码\更新4 岭回归和lasso回归\数据和拓展资料\棉花产量论文作业的数据.xlsx'</span>)</span><br><span class="line">    s = ex.active</span><br><span class="line">    x = np.zeros(shape=(<span class="number">18</span>,<span class="number">5</span>))</span><br><span class="line">    y = np.ones(<span class="number">18</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>,<span class="number">20</span>):</span><br><span class="line">        y[i<span class="number">-2</span>] = s.cell(i,<span class="number">2</span>).value</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">3</span>,<span class="number">8</span>):</span><br><span class="line">            x[i<span class="number">-2</span>][j<span class="number">-3</span>] = s.cell(i,j).value</span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">22</span>)</span><br><span class="line">    alphas = np.logspace(<span class="number">-4</span>,<span class="number">4</span>,<span class="number">200</span>)</span><br><span class="line">    model = LassoCV(alphas=alphas).fit(x_train, y_train)</span><br><span class="line">    print(<span class="string">'最佳的alpha值为：'</span>,model.alpha_)</span><br><span class="line">    <span class="comment"># 系数打印为0则说明对应的因素被筛除</span></span><br><span class="line">    coef = model.coef_</span><br><span class="line">    print(coef)</span><br><span class="line">    x_data = []</span><br><span class="line">    y_data = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        <span class="keyword">if</span> coef[i] == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            x_data.append(s.cell(<span class="number">1</span>,i+<span class="number">3</span>).value)</span><br><span class="line">            y_data.append(coef[i])</span><br><span class="line">    barh_width = <span class="number">0.3</span></span><br><span class="line">    plt.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimHei'</span>]  <span class="comment"># 显示中文标签</span></span><br><span class="line">    plt.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br><span class="line">    plt.barh(y=range(len(x_data)),width=y_data,label=<span class="string">'回归系数'</span>,color=<span class="string">'steelblue'</span>,alpha=<span class="number">0.8</span>,height=barh_width)</span><br><span class="line">    <span class="keyword">for</span> _y, _x <span class="keyword">in</span> enumerate(y_data):</span><br><span class="line">        plt.text(_x+<span class="number">5000</span>,_y+barh_width/<span class="number">2</span>, <span class="string">'%s'</span> % _x, ha=<span class="string">'center'</span>, va=<span class="string">'bottom'</span>)</span><br><span class="line">    plt.yticks(np.arange(len(x_data))+barh_width/<span class="number">2</span>, x_data)</span><br><span class="line">    plt.title(<span class="string">'影响因素的系数图'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'coef'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'categories'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="comment"># 预测</span></span><br><span class="line">    y_predict = model.predict(x_test)</span><br><span class="line">    print(<span class="string">'预测值为：'</span>,y_predict)</span><br><span class="line">    print(<span class="string">'真实值为：'</span>,y_test)</span><br><span class="line">    print(<span class="string">'R^2 为：'</span>,r2_score(y_test, y_predict))</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>







</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">NS</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yoursite.com/2021/03/14/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/">http://yoursite.com/2021/03/14/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yoursite.com" target="_blank">Night Stalker</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/">数学建模</a></div><div class="post_share"><div class="social-share" data-image="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/03/20/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/"><img class="prev-cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">时间序列分析</div></div></a></div><div class="next-post pull-right"><a href="/2021/03/13/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E5%92%8C%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/"><img class="next-cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">相关系数和假设检验</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2021/03/22/主成分分析/" title="主成分分析"><img class="relatedPosts_cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-22</div><div class="relatedPosts_title">主成分分析</div></div></a></div><div class="relatedPosts_item"><a href="/2020/03/13/典型相关分析/" title="典型相关分析"><img class="relatedPosts_cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-03-13</div><div class="relatedPosts_title">典型相关分析</div></div></a></div><div class="relatedPosts_item"><a href="/2021/03/23/因子分析模型/" title="因子分析模型"><img class="relatedPosts_cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-23</div><div class="relatedPosts_title">因子分析模型</div></div></a></div><div class="relatedPosts_item"><a href="/2020/03/22/奇异值分解和图形处理/" title="奇异值分解和图形处理"><img class="relatedPosts_cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-03-22</div><div class="relatedPosts_title">奇异值分解和图形处理</div></div></a></div><div class="relatedPosts_item"><a href="/2021/03/06/插值算法和拟合算法/" title="插值与拟合"><img class="relatedPosts_cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-06</div><div class="relatedPosts_title">插值与拟合</div></div></a></div><div class="relatedPosts_item"><a href="/2021/03/20/时间序列分析/" title="时间序列分析"><img class="relatedPosts_cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-20</div><div class="relatedPosts_title">时间序列分析</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By NS</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" title="缩小字体"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="简繁转换">繁</button><button id="darkmode" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script>if (document.getElementsByClassName('mermaid').length) {
  loadScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js',function () {
    mermaid.initialize({
      theme: 'butterfly',
  })
})
}</script></body></html>