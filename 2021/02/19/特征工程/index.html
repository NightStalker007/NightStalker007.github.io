<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>特征工程 | Night Stalker</title><meta name="description" content="数据集来源使用sklearn.datasets加载流行数据集，datasets.load_()下载小规模数据集，datasets.fetch_\()获取大规模数据集； 例如： 1234sklearn.datasets.load_iris()sklearn.datasets,load_boston()sklearn.datasets.fetch_20newsgroups(data_home&#x3D;None"><meta name="keywords" content="机器学习"><meta name="author" content="NS"><meta name="copyright" content="NS"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://yoursite.com/2021/02/19/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="特征工程"><meta property="og:url" content="http://yoursite.com/2021/02/19/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"><meta property="og:site_name" content="Night Stalker"><meta property="og:description" content="数据集来源使用sklearn.datasets加载流行数据集，datasets.load_()下载小规模数据集，datasets.fetch_\()获取大规模数据集； 例如： 1234sklearn.datasets.load_iris()sklearn.datasets,load_boston()sklearn.datasets.fetch_20newsgroups(data_home&#x3D;None"><meta property="og:image" content="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><meta property="article:published_time" content="2021-02-18T16:00:00.000Z"><meta property="article:modified_time" content="2021-02-20T11:14:14.347Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="prev" title="分类算法" href="http://yoursite.com/2021/02/20/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"><link rel="next" title="logistic回归" href="http://yoursite.com/2021/02/13/logistic%E5%9B%9E%E5%BD%92/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=2700190935,3142448700&amp;fm=26&amp;gp=0.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">19</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">7</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">4</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据集"><span class="toc-number">1.</span> <span class="toc-text">数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#来源"><span class="toc-number">1.1.</span> <span class="toc-text">来源</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#划分"><span class="toc-number">1.2.</span> <span class="toc-text">划分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特征工程"><span class="toc-number">2.</span> <span class="toc-text">特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#特征提取"><span class="toc-number">2.1.</span> <span class="toc-text">特征提取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#文本特征提取"><span class="toc-number">2.2.</span> <span class="toc-text">文本特征提取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tf-idf文本特征提取"><span class="toc-number">2.3.</span> <span class="toc-text">Tf-idf文本特征提取</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特征预处理"><span class="toc-number">3.</span> <span class="toc-text">特征预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#归一化"><span class="toc-number">3.1.</span> <span class="toc-text">归一化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#归一化缺陷"><span class="toc-number">3.2.</span> <span class="toc-text">归一化缺陷</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#标准化"><span class="toc-number">3.3.</span> <span class="toc-text">标准化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特征降维"><span class="toc-number">4.</span> <span class="toc-text">特征降维</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#方法"><span class="toc-number">4.1.</span> <span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#低方差特征过滤"><span class="toc-number">4.1.1.</span> <span class="toc-text">低方差特征过滤</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#相关系数"><span class="toc-number">4.1.2.</span> <span class="toc-text">相关系数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#主成分分析"><span class="toc-number">5.</span> <span class="toc-text">主成分分析</span></a></li></ol></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Night Stalker</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down menus-expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">特征工程</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2021-02-19 00:00:00"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2021-02-19</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2021-02-20 19:14:14"><i class="fas fa-history fa-fw"></i> 更新于 2021-02-20</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><h3 id="来源"><a href="#来源" class="headerlink" title="来源"></a>来源</h3><p>使用sklearn.datasets加载流行数据集，datasets.load_<em>()下载小规模数据集，datasets.fetch_\</em>()获取大规模数据集；</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sklearn.datasets.load_iris()</span><br><span class="line">sklearn.datasets,load_boston()</span><br><span class="line">sklearn.datasets.fetch_20newsgroups(data_home=<span class="literal">None</span>,subset=<span class="string">'train'</span>)</span><br><span class="line"><span class="comment">#subset可以选择要加载的数据集，'train','test','all'（训练集，测试集，所有）</span></span><br></pre></td></tr></table></figure>

<p>load和fetch返回的数据类型为datasets.base.Bunch,是一种字典格式；</p>
<p>包含键：</p>
<p>data：特征数据数组，是$[n_samples*n_features]$的二维numpy.ndarray数组<br>target：标签数组，是$n_samples$的一维numpy.ndarray数组<br>DESCR：数据描述<br>feature_names：特征的名字<br>target_names：标签名</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">datasets_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 获取数据集</span></span><br><span class="line">    iris = load_iris()</span><br><span class="line">    <span class="comment"># print("鸢尾花数据集:\n",iris)</span></span><br><span class="line">    <span class="comment"># print("数据集描述：\n", iris["DESCR"])</span></span><br><span class="line">    <span class="comment"># print("标签数组：\n",iris["target"])</span></span><br><span class="line">    <span class="comment"># print("数据集：\n",iris.data,iris.data.shape)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集划分</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">22</span>)</span><br><span class="line">    print(<span class="string">"训练集特征值：\n"</span>,x_train,x_train.shape)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>



<h3 id="划分"><a href="#划分" class="headerlink" title="划分"></a>划分</h3><p>机器学习一般的数据集会划分为两个部分：</p>
<ul>
<li>训练数据：用于训练构建模型</li>
<li>测试数据：在模型检验时使用，评估模型的有效性</li>
</ul>
<p>大概划分$70%-80%$为训练数据</p>
<p>划分方式：sklearn.model_selection.train_test_split(arrays,*options)</p>
<ul>
<li>x数据集的特征值</li>
<li>y数据集的标签值</li>
<li>test_size测试集的大小(默认0.25)</li>
<li>random_state随机数种子</li>
<li>return 训练集特征值(x_train)，测试集特征值(x_test)，训练集目标值(y_train)，测试集目标值(y_test)（注意顺序）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">22</span>)</span><br><span class="line">print(<span class="string">"训练集特征值：\n"</span>,x_train,x_train.shape)</span><br></pre></td></tr></table></figure>



<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><p>特征提取的过程就是将任意数据/文本/图转换为可用于机器学习的数字特征，特征提取API：sklearn.feature_extraction</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_extraction.DictVectorizer(sparse=<span class="literal">True</span>,...)</span><br></pre></td></tr></table></figure>

<p>用法：</p>
<ul>
<li>DictVectorizer.fit_transform(X):X为字典或包含字典的迭代器返回值，调用返回一个sparse矩阵</li>
<li>DictVectorizer.inverse_transform(X):X为array数组或者sparse矩阵，调用返回原数据格式</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dict_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    字典特征抽取</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [&#123;<span class="string">'city'</span>:<span class="string">'Beijing'</span>,<span class="string">'temperature'</span>:<span class="number">100</span>&#125;,&#123;<span class="string">'city'</span>:<span class="string">'Shanghai'</span>,<span class="string">'temperature'</span>:<span class="number">60</span>&#125;,</span><br><span class="line">            &#123;<span class="string">'city'</span>:<span class="string">'Wuhan'</span>,<span class="string">'temperature'</span>:<span class="number">40</span>&#125;]</span><br><span class="line">    <span class="comment"># 实例化转换器类</span></span><br><span class="line">    transfer = DictVectorizer()</span><br><span class="line">    <span class="comment"># 调用</span></span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    print(<span class="string">"data_new:\n"</span>,data_new)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">data_new:</span></span><br><span class="line"><span class="string">   (0, 0)	1.0</span></span><br><span class="line"><span class="string">  (0, 3)	100.0</span></span><br><span class="line"><span class="string">  (1, 1)	1.0</span></span><br><span class="line"><span class="string">  (1, 3)	60.0</span></span><br><span class="line"><span class="string">  (2, 2)	1.0</span></span><br><span class="line"><span class="string">  (2, 3)	40.0</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>

<p>默认情况下DictVectorizer()的参数parse为True，返回的是稀疏矩阵;</p>
<p>更换语句打印常规矩阵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">transfer = DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">data_new:</span></span><br><span class="line"><span class="string"> [[  1.   0.   0. 100.]</span></span><br><span class="line"><span class="string"> [  0.   1.   0.  60.]</span></span><br><span class="line"><span class="string"> [  0.   0.   1.  40.]]</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>

<h3 id="文本特征提取"><a href="#文本特征提取" class="headerlink" title="文本特征提取"></a>文本特征提取</h3><p>对文本进行特征值化的API：sklearn.feature_extraction.text.CountVectorizer(stop_words=[])</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    文本特征抽取</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = [<span class="string">"life is short, i like python"</span>,<span class="string">"life is too long, i dislike python"</span>]</span><br><span class="line">    transfer = CountVectorizer()</span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    print(<span class="string">"特征名：\n"</span>,transfer.get_feature_names())</span><br><span class="line">    print(<span class="string">"data_new:\n"</span>,data_new.toarray(),type(data_new))</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">特征名：</span></span><br><span class="line"><span class="string"> ['dislike', 'is', 'life', 'like', 'long', 'python', 'short', 'too']</span></span><br><span class="line"><span class="string">data_new:</span></span><br><span class="line"><span class="string"> [[0 1 1 1 0 1 1 0]</span></span><br><span class="line"><span class="string"> [1 1 1 0 1 1 0 1]] &lt;class 'scipy.sparse.csr.csr_matrix'&gt;</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>

<p>中文提取时需要空格分词。stop_words作为停用词，指不会对特征提取结果有贡献的词汇，就不需加入提取结果。</p>
<p>首先借用jieba库进行自动分词，然后再进行提取：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cut_word</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">" "</span>.join(list(jieba.cut(text)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ChineseCount_demo</span><span class="params">()</span>:</span></span><br><span class="line">    data = [<span class="string">"新闻，也叫消息，是指报纸、电台、电视台、互联网经常使用的记录社会、传播信息、反映时代的一种文体，"</span></span><br><span class="line">            <span class="string">"具有真实性、时效性、简洁性、可读性、准确性的特点。新闻概念有广义与狭义之分。"</span></span><br><span class="line">            <span class="string">"就其广义而言，除了发表于报刊、广播、电视上的评论与专文外的常用文本都属于新闻之列，包括消息、通讯、特写、速写（有的将速写纳入特写之列）等等。"</span>]</span><br><span class="line">    data_new = []</span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> data:</span><br><span class="line">        data_new.append(cut_word(sentence))</span><br><span class="line">    <span class="comment"># print(data_new)</span></span><br><span class="line">    transfer = CountVectorizer(stop_words=[<span class="string">"一种"</span>,<span class="string">"一般"</span>,<span class="string">"而言"</span>])</span><br><span class="line">    data_final = transfer.fit_transform((data_new))</span><br><span class="line">    print(<span class="string">"data_final:\n"</span>,data_final.toarray())</span><br><span class="line">    print(<span class="string">"特征名字:\n"</span>,transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>

<h3 id="Tf-idf文本特征提取"><a href="#Tf-idf文本特征提取" class="headerlink" title="Tf-idf文本特征提取"></a>Tf-idf文本特征提取</h3><p>如果某词语在文章中出现频率极高，在其他文章中很少出现，bane这些词语很可能是这篇文章中的关键字；</p>
<p>Tf就是词频（term frequency），给定词语在文章中出现的频率；</p>
<p>idf就是逆向文档频率，是一个词语的普遍重要性的度量，可以由<strong>总文件数目</strong>除以<strong>包含该词语的文件的数目</strong>，在将得到的商取以10位底的对数得到；</p>
<p>eg:</p>
<ul>
<li><p>1000篇文章</p>
</li>
<li><p>100篇文章出现“非常”</p>
</li>
<li><p>10篇文章出现“经济“</p>
</li>
<li><p>文章A：100词，出现10次“经济”，其Tf为$10/100=0.1$；idf为$lg(1000/100)=1$;那么tf-idf为$tf*idf=0.1$,用其代表重要程度；</p>
</li>
</ul>
<p>API：sklearn.feature_extraction.text.TfidfVectorizer(stop_words=None,…)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tfidf_demo</span><span class="params">()</span>:</span></span><br><span class="line">    data = [<span class="string">"新闻，也叫消息，是指报纸、电台、电视台、互联网经常使用的记录社会、传播信息、反映时代的一种文体，"</span></span><br><span class="line">            <span class="string">"具有真实性、时效性、简洁性、可读性、准确性的特点。新闻概念有广义与狭义之分。"</span></span><br><span class="line">            <span class="string">"就其广义而言，除了发表于报刊、广播、电视上的评论与专文外的常用文本都属于新闻之列，包括消息、通讯、特写、速写（有的将速写纳入特写之列）等等。"</span>]</span><br><span class="line">    data_new = []</span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> data:</span><br><span class="line">        data_new.append(cut_word(sentence))</span><br><span class="line">    <span class="comment"># print(data_new)</span></span><br><span class="line">    transfer = TfidfVectorizer(stop_words=[<span class="string">"一种"</span>, <span class="string">"一般"</span>, <span class="string">"而言"</span>])</span><br><span class="line">    data_final = transfer.fit_transform((data_new))</span><br><span class="line">    print(<span class="string">"data_final:\n"</span>, data_final.toarray())</span><br><span class="line">    print(<span class="string">"特征名字:\n"</span>, transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>



<h2 id="特征预处理"><a href="#特征预处理" class="headerlink" title="特征预处理"></a>特征预处理</h2><p>数值型数据的无量纲化包括归一化和标准化；</p>
<p>特征处理API为:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing</span><br></pre></td></tr></table></figure>

<p>特征归一化/标准化的目的：特征的<strong>单位或者大小相差太大</strong>，或者<strong>某特征的方差相比其他的特征要大出几个数量级</strong>，容易影响目标结果，使得一些算法无法学习到其他特征。</p>
<h3 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h3><p>通过对原始数据的变换使得数据映射到[0,1]间；</p>
<p>公式:<br>$$<br>X’ = \frac{x-min}{max-min}，X’’ = X’*(mx-mi)+mi<br>$$<br>对于一个特定的特征对应的数据集，$max,min$分别指代最大数据和最小数据，而$mx,mi$是所要投射去的区间的最大值与最小值，一般取$1,0$，</p>
<p>归一化时用到的API:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.MinMaxScaler(feature_range=(<span class="number">0</span>,<span class="number">1</span>)...)</span><br><span class="line"><span class="comment"># MinMaxScalar.fit_transform(X)，X为numpy array格式的数据[n_samples,n_features]</span></span><br><span class="line"><span class="comment"># 返回值：转换后的形状相同的array</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minmax_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 归一化</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = pd.read_csv(<span class="string">"dt.txt"</span>)</span><br><span class="line">    data = data.iloc[:,:]</span><br><span class="line">    <span class="comment"># 2.实例化转换器类</span></span><br><span class="line">    transfer = MinMaxScaler((<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 3.调用fit_transfer</span></span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    print(<span class="string">"data_new:\n"</span>,data_new)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>

<h3 id="归一化缺陷"><a href="#归一化缺陷" class="headerlink" title="归一化缺陷"></a>归一化缺陷</h3><p>归一化由于直接由极差限制划分区间，因此受误差数据的影响较大，所以这种方法鲁棒性较差，只适合传统精确小数据场景</p>
<h3 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h3><p>通过对数据进行变换使数据集变换到均值为0，标准差为1的范围内；</p>
<p>公式：<br>$$<br>X’=\frac{x-mean}{\sigma}<br>$$</p>
<blockquote>
<p>作用于每一列，mean为均值，$\sigma$为标准差</p>
</blockquote>
<p>这时，如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差改变较小。</p>
<p>API:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.StandardScaler()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">standard_demo</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 标准化</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = pd.read_csv(<span class="string">"dt.txt"</span>)</span><br><span class="line">    data = data.iloc[:, :]</span><br><span class="line">    <span class="comment"># 2.实例化转换器类</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    <span class="comment"># 3.调用fit_transfer</span></span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    print(<span class="string">"data_new:\n"</span>, data_new)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>

<p>它更适合现代的大数据场景。</p>
<h2 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h2><p><strong>降维</strong>是指在某些限定条件下，降低<strong>随机变量（特征）</strong>的个数，得到一组“不相关”的主变量的过程。</p>
<p>降维的方式：</p>
<ul>
<li>特征选择</li>
<li>主成分分析</li>
</ul>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ul>
<li><p>Filter(过滤式)：主要探究特征本身特点，特征与特征和目标值之间关联</p>
<ul>
<li>方差选择法：低方差特征过滤</li>
<li>相关系数</li>
</ul>
</li>
<li><p>Embedded(嵌入式)：算法自动选择特征</p>
<ul>
<li>决策树：信息熵，信息增益</li>
<li>正则化：L1，L2;</li>
<li>深度学习：卷积</li>
</ul>
</li>
</ul>
<h4 id="低方差特征过滤"><a href="#低方差特征过滤" class="headerlink" title="低方差特征过滤"></a>低方差特征过滤</h4><p>特征方差小说明某个特征大多数样本的值都比较接近；</p>
<p>API:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_selection.VarianceThreshold(threshold = <span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>删除所有低方差特征</li>
<li>Variance.fit_transform(X)<ul>
<li>numpy array格式的数据[n_samples,n_features]</li>
<li>返回值：训练集中差异低于threshold的特征将被删除，默认值是保留所有非零方差特征，即只删除所有样本中具有相同值的特征。</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">variance_demo</span><span class="params">()</span>:</span></span><br><span class="line">    data = pd.read_csv(<span class="string">"dt.txt"</span>)</span><br><span class="line">    data = data.iloc[:,:]</span><br><span class="line">    transfer = VarianceThreshold(threshold=<span class="number">5</span>)</span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    print(<span class="string">"data_new\n"</span>,data_new)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>



<h4 id="相关系数"><a href="#相关系数" class="headerlink" title="相关系数"></a>相关系数</h4><p><a href="https://zhuanlan.zhihu.com/p/67961875?utm_source=wechat_session" target="_blank" rel="noopener">相关系数</a></p>
<p>$|r|&lt;0.4$为低度相关，$0.4\leq|r|&lt;0.7$为显著相关，$0.7\leq|r|$为高度线性相关；</p>
<p>API：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br></pre></td></tr></table></figure>

<p>方法就是直接传入数据中所要计算相关系数的两个特征对应列的数据即可；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">r = pearsonr(data[<span class="string">'size'</span>],data[<span class="string">'comfort'</span>])</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">size,population,comfort</span></span><br><span class="line"><span class="string">3,6,9</span></span><br><span class="line"><span class="string">4,3,7</span></span><br><span class="line"><span class="string">1,3,12</span></span><br><span class="line"><span class="string">6,6,3</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Output:</span></span><br><span class="line"><span class="string">r= (-0.9968461286620519, 0.0031538713379480887)</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure>

<h2 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h2><p>高维数据转化为低维数据的过程，作用是将数据维数压缩，尽可能降低原数据的维数，损失少量信息。</p>
<p>API:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sklearn.decomposition.PCA(n_components=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># n_components若为浮点数则说明希望保留百分之多少的信息，若为整数则表示希望减少到多少特征</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PCA_demo</span><span class="params">()</span>:</span></span><br><span class="line">    data = [[<span class="number">2</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>],[<span class="number">6</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">8</span>],[<span class="number">5</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">1</span>]]</span><br><span class="line">    transfer1 = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">    data_new = transfer1.fit_transform(data)</span><br><span class="line">    print(<span class="string">"data_new:\n"</span>,data_new)</span><br><span class="line">    transfer2 = PCA(n_components=<span class="number">0.95</span>)</span><br><span class="line">    data_new1 = transfer2.fit_transform(data)</span><br><span class="line">    print(<span class="string">"data_new1:\n"</span>,data_new1)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>



</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">NS</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yoursite.com/2021/02/19/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">http://yoursite.com/2021/02/19/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yoursite.com" target="_blank">Night Stalker</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post_share"><div class="social-share" data-image="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/02/20/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95/"><img class="prev-cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">分类算法</div></div></a></div><div class="next-post pull-right"><a href="/2021/02/13/logistic%E5%9B%9E%E5%BD%92/"><img class="next-cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">logistic回归</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2021/02/13/logistic回归/" title="logistic回归"><img class="relatedPosts_cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-02-13</div><div class="relatedPosts_title">logistic回归</div></div></a></div><div class="relatedPosts_item"><a href="/2021/02/27/TensorFlow学习笔记/" title="TensorFlow学习笔记"><img class="relatedPosts_cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-02-27</div><div class="relatedPosts_title">TensorFlow学习笔记</div></div></a></div><div class="relatedPosts_item"><a href="/2021/02/20/分类算法/" title="分类算法"><img class="relatedPosts_cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-02-20</div><div class="relatedPosts_title">分类算法</div></div></a></div><div class="relatedPosts_item"><a href="/2021/02/06/机器学习-线性回归/" title="机器学习-梯度下降"><img class="relatedPosts_cover" data-src="https://pic4.zhimg.com/v2-7cfc909ebe8d83683909846edd6b5232_r.jpg?source=1940ef5c"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2021-02-06</div><div class="relatedPosts_title">机器学习-梯度下降</div></div></a></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By NS</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" title="缩小字体"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="简繁转换">繁</button><button id="darkmode" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script>if (document.getElementsByClassName('mermaid').length) {
  loadScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js',function () {
    mermaid.initialize({
      theme: 'default',
  })
})
}</script></body></html>